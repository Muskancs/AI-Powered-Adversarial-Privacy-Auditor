# ğŸ”’ Adversarial Privacy Auditing Framework

This repository contains the implementation of a **comprehensive adversary-aware privacy auditing framework**.  
The framework integrates **classical anonymization**, **differential privacy**, **adversarial attack simulations**, and a **conversational AI assistant** to help researchers, practitioners, and policymakers evaluate privacy risks while maintaining data utility.  

---

## ğŸš€ Features
- âœ… **Anonymization Techniques** â€“ k-anonymity, l-diversity, t-closeness, and differential privacy  
- âœ… **Adversarial Testing** â€“ Membership Inference Attacks (MIA), Attribute Inference Attacks (AIA), and Reconstruction attacks  
- âœ… **Privacyâ€“Utility Trade-off Analysis** â€“ Measure re-identification risk vs. dataset usability  
- âœ… **Conversational AI Assistant** â€“ Interactive chatbot for guidance and explanation of privacy outcomes  
- âœ… **Modular Design** â€“ Easy to extend with new datasets, anonymization methods, or attack models  

---

## ğŸ“‚ Repository Structure
```bash
â”œâ”€â”€ data/                 # Sample synthetic and real-world datasets (anonymized)
â”œâ”€â”€ notebooks/            # Jupyter notebooks for experiments and analysis
â”œâ”€â”€ src/                  # Core framework source code
â”‚   â”œâ”€â”€ anonymization/    # k-anonymity, l-diversity, t-closeness, DP modules
â”‚   â”œâ”€â”€ attacks/          # MIA, AIA, reconstruction attack simulations
â”‚   â”œâ”€â”€ tradeoff/         # Privacyâ€“utility trade-off metrics and visualization
â”‚   â”œâ”€â”€ chatbot/          # Conversational AI assistant implementation
â”‚   â””â”€â”€ utils/            # Helper scripts
â”œâ”€â”€ results/              # Experiment results, figures, and tables
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
```

âš™ï¸ Installation

1. Clone the repository:

git clone https://github.com/your-username/privacy-auditor.git
cd privacy-auditor


2. Create a virtual environment (recommended):

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows


3. Install dependencies:

pip install -r requirements.txt

ğŸ§ª Usage

Run experiments on sample datasets:

python src/main.py --dataset data/military.csv --method k-anonymity --k 5


Run adversarial simulations:

python src/main.py --dataset data/bank.csv --attack mia


Launch the chatbot assistant:

python src/chatbot/app.py

ğŸ“Š Example Results (Table 7.1)

The framework was tested across multiple datasets. The results demonstrate how anonymization and adversarial testing reduce risks while maintaining data utility.

| Metric                        | Military | Bank   | Medical |
|--------------------------------|----------|--------|---------|
| Raw Overall Risk (0â€“100)       | 3.50     | 68.21  | 29.46   |
| Anonymized Overall Risk (0â€“100)| 0.55     | 18.38  | 0.13    |
| MIA Accuracy (Raw)             | 0.373    | 0.830  | 0.859   |
| MIA Accuracy (Anon)            | 0.007    | 0.599  | 0.000   |

ğŸ—ï¸ Tech Stack

Python 3.10+

pandas â€“ data handling

scikit-learn â€“ ML-based utility evaluation

PyTorch â€“ adversarial attack models

transformers â€“ conversational AI assistant

ğŸ“Œ Future Work

Adaptive anonymization using reinforcement learning

Distributed adversarial simulations for scalability

Policy-aware chatbot guidance for GDPR/HIPAA compliance

ğŸ¤ Contributing

Contributions are welcome!
Please fork this repository, create a new branch, and submit a pull request.

ğŸ“§ Contact & ğŸŒ Connect

ğŸ“§ Contact: [Muskan Bisht](mailto:muskanbisht02@gmail.com)

LinkedIn: [https://www.linkedin.com/in/muskan-bisht-b143702b3/](https://www.linkedin.com/in/muskan-bisht-b143702b3/)


---

âœ… This is a single **ready-to-use README**.  

Do you also want me to generate a **requirements.txt** with pinned versions so anyone can just install and run the repo without dependency errors?
